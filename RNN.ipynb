{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davottakvota/PredictFrameRNN/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Монтируем Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K3l6hc64Otym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "MAX_FRAMES = 10  # Максимальная длина последовательности\n",
        "MIN_FRAMES = 4\n",
        "\n",
        "HEIGHT = 64\n",
        "WIDTH = 64\n",
        "CHANNELS = 1"
      ],
      "metadata": {
        "id": "u3KLWgwzaxQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Функция для создания последовательностей из видео\n",
        "def create_sequences_from_video(video, min_frames=MIN_FRAMES, max_frames=MAX_FRAMES):\n",
        "    \"\"\"Генератор, создающий последовательности из одного видео\"\"\"\n",
        "    n_frames = video.shape[0]\n",
        "    for start_idx in range(min_frames-1, n_frames - 1):\n",
        "        seq_length = np.random.randint(min_frames, min(max_frames, start_idx + 1) + 1)\n",
        "        end_idx = start_idx + seq_length\n",
        "        if end_idx >= n_frames:\n",
        "            continue\n",
        "\n",
        "        input_seq = video[start_idx:end_idx]\n",
        "        target_frame = video[end_idx]\n",
        "\n",
        "        # Дополняем последовательность нулями\n",
        "        padded_seq = np.zeros((max_frames, 64, 64, 1), dtype=np.float32)\n",
        "        padded_seq[:len(input_seq)] = input_seq\n",
        "\n",
        "        yield padded_seq, target_frame\n",
        "\n",
        "# Функция-генератор для всего датасета\n",
        "def dataset_generator(split='test', indices=None):\n",
        "    ds = tfds.load('moving_mnist', split=split)\n",
        "    for i, example in enumerate(tfds.as_numpy(ds)):\n",
        "        # Если указаны индексы и текущий индекс не входит в список - пропускаем\n",
        "        if indices is not None and i not in indices:\n",
        "            continue\n",
        "\n",
        "        video = example['image_sequence'] / 255.0\n",
        "        for seq, target in create_sequences_from_video(video):\n",
        "            yield seq, target\n",
        "\n",
        "# Создаем полный набор индексов\n",
        "ds = tfds.load('moving_mnist', split='test')\n",
        "total_videos = ds.cardinality().numpy()\n",
        "all_indices = list(range(total_videos))"
      ],
      "metadata": {
        "id": "0irNpG2II6Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "dirs=(\n",
        "    \"/content/drive/My Drive/checkweightsRNN\"\n",
        ")\n",
        "\n",
        "for dir in \"${dirs[@]}\"; do\n",
        "    if [ ! -d \"$dir\" ]; then\n",
        "        mkdir -p \"$dir\"\n",
        "        echo \"✅ Создана папка: $dir\"\n",
        "    else\n",
        "        echo \"ℹ️ Папка уже существует: $dir\"\n",
        "    fi\n",
        "done"
      ],
      "metadata": {
        "id": "j4ZEjNBrM45t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделяем индексы вместо данных\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "bmL9CuCmJir5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем tf.data.Dataset из генераторов\n",
        "def create_dataset(indices, batch_size=BATCH_SIZE):\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        lambda: dataset_generator('test', indices),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(MAX_FRAMES, 64, 64, 1)),\n",
        "            tf.TensorSpec(shape=(64, 64, 1)))\n",
        "\n",
        "    ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Создаем тренировочный и тестовый наборы данных\n",
        "train_dataset = create_dataset(train_indices)\n",
        "test_dataset = create_dataset(test_indices)\n",
        "\n",
        "# Оптимизированная архитектура модели без TimeDistributed и маскирования\n",
        "def build_moving_mnist_model():\n",
        "    inputs = layers.Input(shape=(MAX_FRAMES, 64, 64, 1))\n",
        "\n",
        "    # Убираем маскирующий слой\n",
        "    # Вместо этого будем использовать нулевое дополнение\n",
        "\n",
        "    # Первый ConvLSTM слой\n",
        "    x = layers.ConvLSTM2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        padding='same',\n",
        "        return_sequences=True\n",
        "    )(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Второй ConvLSTM слой\n",
        "    x = layers.ConvLSTM2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        padding='same',\n",
        "        return_sequences=False\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Декодер\n",
        "    x = layers.Conv2D(64, 3, activation='leaky_relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    outputs = layers.Conv2D(\n",
        "        filters=1,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        activation='sigmoid'\n",
        "    )(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "model = build_moving_mnist_model()\n",
        "model.summary()\n",
        "\n",
        "# Callback'и\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)\n",
        "]\n"
      ],
      "metadata": {
        "id": "DNtrc-6QJhRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение с уменьшенными параметрами\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=300,       # Уменьшаем количество шагов\n",
        "    validation_steps=100        # Уменьшаем валидационные шаги\n",
        ")"
      ],
      "metadata": {
        "id": "UwU2tXIEP8EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss Evolution')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['mae'], label='Training MAE')\n",
        "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "    plt.title('MAE Evolution')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# После обучения\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "9mCpbTcNS3OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_from_sequence(model, initial_frames, total_frames=20):\n",
        "    \"\"\"\n",
        "    Генерирует видео, начиная с заданной последовательности кадров\n",
        "\n",
        "    Параметры:\n",
        "    model: обученная модель предсказания кадров\n",
        "    initial_frames: список начальных кадров (numpy array, shape: [h, w, c])\n",
        "    total_frames: общее количество кадров в итоговом видео\n",
        "\n",
        "    Возвращает:\n",
        "    numpy array всех кадров формы (total_frames, h, w, c)\n",
        "    \"\"\"\n",
        "    # Создаем копию начальных кадров\n",
        "    sequence = initial_frames.copy()\n",
        "    num_initial = len(initial_frames)\n",
        "\n",
        "    # Проверка минимальной длины\n",
        "    if num_initial < 1:\n",
        "        raise ValueError(\"Должен быть хотя бы один начальный кадр\")\n",
        "\n",
        "    # Создаем буфер для входа модели\n",
        "    current_sequence = np.zeros((1, MAX_FRAMES, HEIGHT, WIDTH, CHANNELS), dtype=np.float32)\n",
        "\n",
        "    # Рассчитываем сколько кадров нужно сгенерировать\n",
        "    frames_to_generate = total_frames - num_initial\n",
        "\n",
        "    # Начальное заполнение буфера\n",
        "    start_idx = max(0, num_initial - MAX_FRAMES)\n",
        "    last_frames = sequence[start_idx:num_initial]\n",
        "    current_sequence[0, -len(last_frames):] = last_frames\n",
        "\n",
        "    # Генерация новых кадров\n",
        "    for i in range(frames_to_generate):\n",
        "        # Предсказываем следующий кадр\n",
        "        next_frame = model.predict(current_sequence, verbose=0)[0]\n",
        "        sequence.append(next_frame)\n",
        "\n",
        "        # Обновляем буфер последовательности\n",
        "        if MAX_FRAMES > 1:\n",
        "            # Сдвигаем последовательность влево\n",
        "            current_sequence[0, :-1] = current_sequence[0, 1:]\n",
        "            # Добавляем новый кадр в конец\n",
        "            current_sequence[0, -1] = next_frame\n",
        "\n",
        "    return np.array(sequence)\n",
        "\n",
        "# Загрузка одного видео для тестирования\n",
        "def load_single_video(index=0):\n",
        "    ds = tfds.load('moving_mnist', split='test')\n",
        "    for i, example in enumerate(tfds.as_numpy(ds)):\n",
        "        if i == index:\n",
        "            return example['image_sequence'] / 255.0\n",
        "    return None\n",
        "\n",
        "# Визуализация результатов\n",
        "def visualize_results(real_video, generated_video, num_frames=5):\n",
        "    fig, axes = plt.subplots(2, num_frames, figsize=(15, 6))\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        frame_idx = i * (len(real_video) // num_frames)\n",
        "\n",
        "        # Реальные кадры\n",
        "        axes[0, i].imshow(real_video[frame_idx, :, :, 0], cmap='gray')\n",
        "        axes[0, i].set_title(f\"Real Frame {frame_idx}\")\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # Сгенерированные кадры\n",
        "        axes[1, i].imshow(generated_video[frame_idx, :, :, 0], cmap='gray')\n",
        "        axes[1, i].set_title(f\"Generated Frame {frame_idx}\")\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u9d892njP-qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1AXVkwflOdNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестирование на одном видео\n",
        "test_video = load_single_video(0)\n",
        "if test_video is not None:\n",
        "    first_frames = test_video[:10]\n",
        "    real_video = test_video[:20]\n",
        "\n",
        "    generated_video = generate_video_from_sequence(model, list(first_frames), total_frames=20)\n",
        "    visualize_results(real_video, generated_video)\n",
        "\n",
        "# Сохранение модели в оптимизированном формате\n",
        "model.save(\"/content/drive/My Drive/checkweightsRNN/video_generation_model.keras\", save_format='keras')"
      ],
      "metadata": {
        "id": "wa1MmEYgP67E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_video.shape"
      ],
      "metadata": {
        "id": "UQrhh7sghmEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "def animate(i):\n",
        "  ax.clear()\n",
        "  return ax.imshow(generated_video[i, :, :, 0], cmap='gray')\n",
        "ani = animation.FuncAnimation(fig=fig,\n",
        "                              func=animate,\n",
        "                              frames=generated_video[:, 0, 0, 0].shape[0],\n",
        "                              interval=1000/4,\n",
        "                              blit=False)\n",
        "HTML(ani.to_jshtml())"
      ],
      "metadata": {
        "id": "pRL5DQOThy1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Определяем путь к модели\n",
        "model_path = '/content/drive/My Drive/checkweightsRNN/video_generation_model.keras'\n",
        "\n",
        "# 3. Определяем пользовательские объекты (custom objects)\n",
        "#    Если в модели использовались кастомные слои, функции потерь или метрики\n",
        "# custom_objects = {\n",
        "#     'ssim_loss': ssim_loss,  # Ваша кастомная функция потерь\n",
        "#     'PSNR': PSNR,            # Ваша кастомная метрика\n",
        "#     'SSIM': SSIM,            # Ваша кастомная метрика\n",
        "#     'TemporalAttention': TemporalAttention  # Ваш кастомный слой\n",
        "# }\n",
        "\n",
        "# 4. Загружаем модель\n",
        "import tensorflow as tf\n",
        "loaded_model = tf.keras.models.load_model( model_path\n",
        "    # model_path,\n",
        "    # custom_objects=custom_objects\n",
        ")\n",
        "\n",
        "# 5. Проверяем, что модель загружена корректно\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "tXWtGzamOf2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}